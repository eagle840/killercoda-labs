{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63062cba-f0b3-49a1-9671-3ee554a730f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a494bc4caa049fe9e982201834dbf12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce96b164a574418cb68052958d7be1d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620d495c31dc42c9b0ae239b8a409a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a19d15ac4e42c9a4d4b67ede91aef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁What', '▁color', '▁is', '▁the', '▁un', 'doubtedly', '▁beautiful', '▁sky', '?']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "line = 'What color is the undoubtedly beautiful sky?'\n",
    "\n",
    "model_name = 'google/flan-t5-base'\n",
    "# https://huggingface.co/google/flan-t5-base\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# tokenizer types are dependant on model\n",
    "\n",
    "tokens = tokenizer.tokenize(line)\n",
    "    \n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d96b187-23bf-4029-9e18-0ce9351c004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2237669-99a6-4887-8234-159ce8acd3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(line, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ca75104-54e6-4848-98ac-d751be507a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a18273afcb145a786e6e24107506d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fde74d9db584882a933d475aef1ab43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ed09828ea240bba14a5326df912eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0448738a-4418-429e-9733-bab614bdd52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embeddings = model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f4f0b54-5d49-4163-b141-5838473dd95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  363,   945,    19,     8,    73, 16501,   786,  5796,    58,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b02e775b-3b2d-425b-9ef6-0a092701f300",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = tokens['input_ids'][0]\n",
    "our_embeddings = input_embeddings(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4dfe938-9271-4c8f-9d8b-43b0f5849f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 768])\n"
     ]
    }
   ],
   "source": [
    "print(our_embeddings.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b713065-5bdc-4b89-b5c0-f9c2daa5cfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.2037e+00,  1.5036e+00, -5.7426e-01,  ..., -9.9989e-01,\n",
      "         -1.2127e+00, -2.3358e+00],\n",
      "        [ 1.4202e+00,  8.3666e-01,  1.7161e+01,  ...,  1.0945e+01,\n",
      "          9.9303e+00,  6.6883e+00],\n",
      "        [-1.7532e+00,  1.4827e+00, -4.9316e-01,  ...,  3.4938e+00,\n",
      "         -9.8175e-01, -1.7624e+00],\n",
      "        ...,\n",
      "        [-1.7212e+01, -7.2422e+00,  1.5144e+00,  ..., -1.1926e+01,\n",
      "          3.0918e-01,  1.8786e+00],\n",
      "        [-1.7479e-02, -1.9378e+00, -2.8608e+00,  ...,  2.8803e-01,\n",
      "          7.3407e-02, -9.4383e+00],\n",
      "        [ 1.5827e+01,  7.1912e+00,  1.5141e+01,  ...,  5.4508e+00,\n",
      "         -2.5928e+01,  1.1496e+01]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(our_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78a44c42-af95-4b32-9963-909533e1d57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/llm/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1353: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "679fc5e8-9e92-43a5-a682-a845d996c3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blue']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(outputs, skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
